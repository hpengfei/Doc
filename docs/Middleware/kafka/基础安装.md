## 启动

### 网络配置

```
# curl -L git.io/weave -o /usr/local/bin/weave
# chmod a+x /usr/local/bin/weave
# weave launch
# eval $(weave env)
```

注意：第一个主机执行 `weave launch`，后面每多一台主机添加到weave中需要执行 `weave launch $host1 ... $hostN` 。在新建docker容器之前必须执行 `eval $(weave env)` 命令。

### 启动kafka

```
# tree np-kafka-01
np-kafka-01
├── d
│   └── kafka
│       ├── config
│       │   ├── connect-console-sink.properties
│       │   ├── connect-console-source.properties
│       │   ├── connect-distributed.properties
│       │   ├── connect-file-sink.properties
│       │   ├── connect-file-source.properties
│       │   ├── connect-log4j.properties
│       │   ├── connect-mirror-maker.properties
│       │   ├── connect-standalone.properties
│       │   ├── consumer.properties
│       │   ├── log4j.properties
│       │   ├── producer.properties
│       │   ├── server.properties
│       │   ├── tools-log4j.properties
│       │   ├── trogdor.conf
│       │   └── zookeeper.properties
│       └── logs
└── start.sh
# cat np-kafka-01/start.sh
#!/bin/bash
if [[ $# == 0 ]]; then
        echo "会启动一套系统"
        echo "格式:"
        echo "          $0 192.168.2.100: 5000"
        echo "      容器名为当前目录名"
else
        C_HOSTIP=$1
        PORTSTART=$2
        DIR_NAME=$(pwd)
        C_NAME=$(basename ${DIR_NAME})
        sudo chmod g+rwx -R $(pwd)/d
        sudo chgrp 0 -R $(pwd)/d
        eval $(weave env)
        docker run -t -d -i --name ${C_NAME} --hostname ${C_NAME}.weave.local \
                --privileged \
                --restart=unless-stopped \
                --ulimit nofile=262144:262144 \
                --ulimit memlock=-1:-1 \
                --cpus 1 \
                --memory 2G \
                --env KAFKA_HEAP_OPTS=" -Xmx2048m -Xms2048m" \
                --env KAFKA_ZOOKEEPER_CONNECT=np-zk-01:2181,np-zk-02:2181,np-zk-03:2181 \
                --env KAFKA_ADVERTISED_HOST_NAME=${C_NAME} \
                --env KAFKA_ADVERTISED_PORT=9092 \
                --env KAFKA_BROKER_ID=1 \
                --env KAFKA_JMX_OPTS="-Dcom.sun.management.jmxremote -Dcom.sun.management.jmxremote.authenticate=false -Dcom.sun.management.jmxremote.ssl=false -Djava.rmi.server.hostname=${C_NAME} -Dcom.sun.management.jmxremote.rmi.port=19999" \
                --env JMX_PORT=19999 \
                --env KAFKA_LOG_DIRS=/opt/kafka/logs \
                -v $(pwd)/d/kafka/config:/opt/kafka/config \
                -v $(pwd)/d/kafka/logs:/opt/kafka/logs \
                -p ${C_HOSTIP}19092:9092 \
                -p ${C_HOSTIP}19999:19999 \
                wurstmeister/kafka:2.13-2.7.0
         eval $(weave env --restore)
fi
# egrep -v "^$|^#" np-kafka-01/d/kafka/config/server.properties
broker.id=1                        # 需要修改
acks=all
auto.create.topics.enable=false
default.replication.factor=3
min.insync.replicas=2
enable.auto.commit=false
listeners=PLAINTEXT://0.0.0.0:9092 # 需要修改
num.network.threads=3
num.io.threads=8
socket.send.buffer.bytes=102400
socket.receive.buffer.bytes=102400
socket.request.max.bytes=104857600
log.dirs=/opt/kafka/logs # 需要修改
num.partitions=3         # 需要修改
num.recovery.threads.per.data.dir=1
offsets.topic.replication.factor=3
transaction.state.log.replication.factor=3
transaction.state.log.min.isr=2
log.retention.hours=168
log.segment.bytes=1073741824
log.retention.check.interval.ms=300000
zookeeper.connect=np-zk-01:2181,np-zk-02:2181,np-zk-03:2181
zookeeper.connection.timeout.ms=18000
group.initial.rebalance.delay.ms=0
advertised.port=9092
advertised.host.name=np-kafka-01
port=9092
```

```
# tree np-kafka-02/
np-kafka-02/
├── d
│   └── kafka
│       ├── config
│       │   ├── connect-console-sink.properties
│       │   ├── connect-console-source.properties
│       │   ├── connect-distributed.properties
│       │   ├── connect-file-sink.properties
│       │   ├── connect-file-source.properties
│       │   ├── connect-log4j.properties
│       │   ├── connect-mirror-maker.properties
│       │   ├── connect-standalone.properties
│       │   ├── consumer.properties
│       │   ├── log4j.properties
│       │   ├── producer.properties
│       │   ├── server.properties
│       │   ├── tools-log4j.properties
│       │   ├── trogdor.conf
│       │   └── zookeeper.properties
│       └── logs
└── start.sh
# cat np-kafka-02/start.sh
#!/bin/bash
if [[ $# == 0 ]]; then
        echo "会启动一套系统"
        echo "格式:"
        echo "          $0 192.168.2.100: 5000"
        echo "      容器名为当前目录名"
else
        C_HOSTIP=$1
        PORTSTART=$2
        DIR_NAME=$(pwd)
        C_NAME=$(basename ${DIR_NAME})
        sudo chmod g+rwx -R $(pwd)/d
        sudo chgrp 0 -R $(pwd)/d
        eval $(weave env)
        docker run -t -d -i --name ${C_NAME} --hostname ${C_NAME}.weave.local \
                --privileged \
                --restart=unless-stopped \
                --ulimit nofile=262144:262144 \
                --ulimit memlock=-1:-1 \
                --cpus 1 \
                --memory 2G \
                --env KAFKA_HEAP_OPTS=" -Xmx2048m -Xms2048m" \
                --env KAFKA_ZOOKEEPER_CONNECT=np-zk-01:2181,np-zk-02:2181,np-zk-03:2181 \
                --env KAFKA_ADVERTISED_HOST_NAME=${C_NAME} \
                --env KAFKA_ADVERTISED_PORT=9092 \
                --env KAFKA_BROKER_ID=2 \
                --env KAFKA_JMX_OPTS="-Dcom.sun.management.jmxremote -Dcom.sun.management.jmxremote.authenticate=false -Dcom.sun.management.jmxremote.ssl=false -Djava.rmi.server.hostname=${C_NAME} -Dcom.sun.management.jmxremote.rmi.port=29999" \
                --env JMX_PORT=29999 \
                --env KAFKA_LOG_DIRS=/opt/kafka/logs \
                -v $(pwd)/d/kafka/config:/opt/kafka/config \
                -v $(pwd)/d/kafka/logs:/opt/kafka/logs \
                -p ${C_HOSTIP}29092:9092 \
                -p ${C_HOSTIP}29999:29999 \
                wurstmeister/kafka:2.13-2.7.0
        eval $(weave env --restore)
fi
# egrep -v "^$|^#" np-kafka-02/d/kafka/config/server.properties
broker.id=2                         # 需要修改
acks=all
auto.create.topics.enable=false
default.replication.factor=3
min.insync.replicas=2
enable.auto.commit=false
listeners=PLAINTEXT://0.0.0.0:9092  # 需要修改
num.network.threads=3
num.io.threads=8
socket.send.buffer.bytes=102400
socket.receive.buffer.bytes=102400
socket.request.max.bytes=104857600
log.dirs=/opt/kafka/logs  # 需要修改
num.partitions=3          # 需要修改
num.recovery.threads.per.data.dir=1
offsets.topic.replication.factor=3
transaction.state.log.replication.factor=3
transaction.state.log.min.isr=2
log.retention.hours=168
log.segment.bytes=1073741824
log.retention.check.interval.ms=300000
zookeeper.connect=np-zk-01:2181,np-zk-02:2181,np-zk-03:2181
zookeeper.connection.timeout.ms=18000
group.initial.rebalance.delay.ms=0
advertised.port=9092
advertised.host.name=np-kafka-02
port=9092
```

```
# tree np-kafka-03/
np-kafka-03/
├── d
│   └── kafka
│       ├── config
│       │   ├── connect-console-sink.properties
│       │   ├── connect-console-source.properties
│       │   ├── connect-distributed.properties
│       │   ├── connect-file-sink.properties
│       │   ├── connect-file-source.properties
│       │   ├── connect-log4j.properties
│       │   ├── connect-mirror-maker.properties
│       │   ├── connect-standalone.properties
│       │   ├── consumer.properties
│       │   ├── log4j.properties
│       │   ├── producer.properties
│       │   ├── server.properties
│       │   ├── tools-log4j.properties
│       │   ├── trogdor.conf
│       │   └── zookeeper.properties
│       └── logs
└── start.sh
# cat np-kafka-03/start.sh
#!/bin/bash
if [[ $# == 0 ]]; then
        echo "会启动一套系统"
        echo "格式:"
        echo "          $0 192.168.2.100: 5000"
        echo "      容器名为当前目录名"
else
        C_HOSTIP=$1
        PORTSTART=$2
        DIR_NAME=$(pwd)
        C_NAME=$(basename ${DIR_NAME})
        sudo chmod g+rwx -R $(pwd)/d
        sudo chgrp 0 -R $(pwd)/d
        eval $(weave env)
        docker run -t -d -i --name ${C_NAME} --hostname ${C_NAME}.weave.local \
                --privileged \
                --restart=unless-stopped \
                --ulimit nofile=262144:262144 \
                --ulimit memlock=-1:-1 \
                --cpus 1 \
                --memory 2G \
                --env KAFKA_HEAP_OPTS=" -Xmx2048m -Xms2048m" \
                --env KAFKA_ZOOKEEPER_CONNECT=np-zk-01:2181,np-zk-02:2181,np-zk-03:2181 \
                --env KAFKA_ADVERTISED_HOST_NAME=${C_NAME} \
                --env KAFKA_ADVERTISED_PORT=9092 \
                --env KAFKA_BROKER_ID=3 \
                --env KAFKA_JMX_OPTS="-Dcom.sun.management.jmxremote -Dcom.sun.management.jmxremote.authenticate=false -Dcom.sun.management.jmxremote.ssl=false -Djava.rmi.server.hostname=${C_NAME} -Dcom.sun.management.jmxremote.rmi.port=39999" \
                --env JMX_PORT=39999 \
                --env KAFKA_LOG_DIRS=/opt/kafka/logs \
                -v $(pwd)/d/kafka/config:/opt/kafka/config \
                -v $(pwd)/d/kafka/logs:/opt/kafka/logs \
                -p ${C_HOSTIP}39092:9092 \
                -p ${C_HOSTIP}39999:39999 \
                wurstmeister/kafka:2.13-2.7.0
         eval $(weave env --restore)
fi
# egrep -v "^$|^#" np-kafka-03/d/kafka/config/server.properties
broker.id=3                         # 需要修改
acks=all
auto.create.topics.enable=false
default.replication.factor=3
min.insync.replicas=2
enable.auto.commit=false
listeners=PLAINTEXT://0.0.0.0:9092  # 需要修改
num.network.threads=3
num.io.threads=8
socket.send.buffer.bytes=102400
socket.receive.buffer.bytes=102400
socket.request.max.bytes=104857600
log.dirs=/opt/kafka/logs  # 需要修改
num.partitions=3          # 需要修改
num.recovery.threads.per.data.dir=1
offsets.topic.replication.factor=3
transaction.state.log.replication.factor=3
transaction.state.log.min.isr=2
log.retention.hours=168
log.segment.bytes=1073741824
log.retention.check.interval.ms=300000
zookeeper.connect=np-zk-01:2181,np-zk-02:2181,np-zk-03:2181
zookeeper.connection.timeout.ms=18000
group.initial.rebalance.delay.ms=0
advertised.port=9092
advertised.host.name=np-kafka-03
port=9092
```

## 命令使用

### 创建topic

```
# ./kafka-topics.sh --create --zookeeper 10.10.10.232:12181,10.10.10.233:22181,10.10.10.234:32181 --replication-factor 3 --partitions 3 --topic Test
```

### 查询topic

查看所有主题名：

```
# ./kafka-topics.sh --list --zookeeper 10.10.10.232:12181,10.10.10.233:22181,10.10.10.234:32181
```

查看单个主题信息：

```
# ./kafka-topics.sh --describe --zookeeper 10.10.10.232:12181,10.10.10.233:22181,10.10.10.234:32181 --topic Test
```

查看全部主题信息:

```
# ./kafka-topics.sh --describe --zookeeper 10.10.10.232:12181,10.10.10.233:22181,10.10.10.234:32181
```

查看正在同步的主题：

```
# ./kafka-topics.sh --describe --zookeeper 10.10.10.232:12181,10.10.10.233:22181,10.10.10.234:32181 --under-replicated-partitions
```

如出现“under replicated”这种情况则需要重点关注，这表示Kafka集群的某个代理节点可能已出现异常或者同步的速度减慢。

查看主题中不可用分区：

```
# ./kafka-topics.sh --describe --zookeeper 10.10.10.232:12181,10.10.10.233:22181,10.10.10.234:32181 --unavailable-partitions
```

查看主题重写的配置：

```
# ./kafka-topics.sh --describe --zookeeper 10.10.10.232:12181,10.10.10.233:22181,10.10.10.234:32181 --topics-with-overrides
```

### 修改topic

```
# ./kafka-topics.sh --alter --zookeeper 10.10.10.232:12181,10.10.10.233:22181,10.10.10.234:32181 --topic Test --config xxxx=xxx
```

### 删除topic

```
# ./kafka-topics.sh --delete --zookeeper 10.10.10.232:12181,10.10.10.233:22181,10.10.10.234:32181 --topic Test
```

需要kafka配置 delete.topic.enable=true 才能删除，先版本默认是可以删除的。

### 分区操作

http://kafka.apache.org/documentation/#basic_ops_cluster_expansion

创建topic：

```
# ./kafka-topics.sh --create --zookeeper 10.10.10.232:12181,10.10.10.233:22181,10.10.10.234:32181 --replication-factor 1 --partitions 1 --topic Test --config segment.bytes=104857600
```

查看topic：

```
# ./kafka-topics.sh --describe --zookeeper 10.10.10.232:12181,10.10.10.233:22181,10.10.10.234:32181 --topic Test
Topic: Test     PartitionCount: 1       ReplicationFactor: 1    Configs: segment.bytes=104857600
        Topic: Test     Partition: 0    Leader: 2       Replicas: 2     Isr: 2
```

主题分区只能增加不能减少，下面修改分区：

```
# ./kafka-topics.sh --alter --zookeeper 10.10.10.232:12181,10.10.10.233:22181,10.10.10.234:32181 --topic Test --partitions 6
Topic: Test     PartitionCount: 6       ReplicationFactor: 1    Configs: segment.bytes=104857600
        Topic: Test     Partition: 0    Leader: 2       Replicas: 2     Isr: 2
        Topic: Test     Partition: 1    Leader: 3       Replicas: 3     Isr: 3
        Topic: Test     Partition: 2    Leader: 1       Replicas: 1     Isr: 1
        Topic: Test     Partition: 3    Leader: 2       Replicas: 2     Isr: 2
        Topic: Test     Partition: 4    Leader: 3       Replicas: 3     Isr: 3
        Topic: Test     Partition: 5    Leader: 1       Replicas: 1     Isr: 1
```

修改副本数：

```
{
	"partitions":
	  [
	  	{
	  		"topic": "Test",
	  		"partition": 0,
	  		"replicas": [2,1,3]
	  	},
	  	{
	  		"topic": "Test",
	  		"partition": 1,
	  		"replicas": [3,2,1]
	  	},
	  	{
	  		"topic": "Test",
	  		"partition": 2,
	  		"replicas": [1,3,2]
	  	},
	  	{
	  		"topic": "Test",
	  		"partition": 3,
	  		"replicas": [2,3,1]
	  	},
	  	{
	  		"topic": "Test",
	  		"partition": 4,
	  		"replicas": [3,1,2]
	  	},
	  	{
	  		"topic": "Test",
	  		"partition": 5,
	  		"replicas": [1,2,3]
	  	}
	   ],
	"version": 1
}
```

```
# ./kafka-reassign-partitions.sh --zookeeper 10.10.10.232:12181,10.10.10.233:22181,10.10.10.234:32181 --reassignment-json-file /tmp/Test_replicas.json --execute
Warning: --zookeeper is deprecated, and will be removed in a future version of Kafka.
Current partition replica assignment

{"version":1,"partitions":[{"topic":"Test","partition":0,"replicas":[2],"log_dirs":["any"]},{"topic":"Test","partition":1,"replicas":[3],"log_dirs":["any"]},{"topic":"Test","partition":2,"replicas":[1],"log_dirs":["any"]},{"topic":"Test","partition":3,"replicas":[2],"log_dirs":["any"]},{"topic":"Test","partition":4,"replicas":[3],"log_dirs":["any"]},{"topic":"Test","partition":5,"replicas":[1],"log_dirs":["any"]}]}

Save this to use as the --reassignment-json-file option during rollback
Successfully started partition reassignments for Test-0,Test-1,Test-2,Test-3,Test-4,Test-5
```

verify 参数验证上面计划是否完成：

```
# ./kafka-reassign-partitions.sh --zookeeper 10.10.10.232:12181,10.10.10.233:22181,10.10.10.234:32181 --reassignment-json-file /tmp/Test_replicas.json --verify
Warning: --zookeeper is deprecated, and will be removed in a future version of Kafka.
Warning: because you are using the deprecated --zookeeper option, the results may be incomplete.  Use --bootstrap-server instead for more accurate results.
Status of partition reassignment:
Reassignment of partition Test-0 is complete.
Reassignment of partition Test-1 is complete.
Reassignment of partition Test-2 is complete.
Reassignment of partition Test-3 is complete.
Reassignment of partition Test-4 is complete.
Reassignment of partition Test-5 is complete.
Clearing broker-level throttles on brokers 1,2,3
Clearing topic-level throttles on topic Test
```

通过 describe 查看主题  Test 的分区是否修改成功：

```
# ./kafka-topics.sh --describe --zookeeper 10.10.10.232:12181,10.10.10.233:22181,10.10.10.234:32181 --topic Test
Topic: Test     PartitionCount: 6       ReplicationFactor: 3    Configs: segment.bytes=104857600
        Topic: Test     Partition: 0    Leader: 2       Replicas: 2,1,3 Isr: 2,1,3
        Topic: Test     Partition: 1    Leader: 3       Replicas: 3,2,1 Isr: 3,2,1
        Topic: Test     Partition: 2    Leader: 1       Replicas: 1,3,2 Isr: 1,2,3
        Topic: Test     Partition: 3    Leader: 2       Replicas: 2,3,1 Isr: 2,3,1
        Topic: Test     Partition: 4    Leader: 3       Replicas: 3,1,2 Isr: 3,2,1
        Topic: Test     Partition: 5    Leader: 1       Replicas: 1,2,3 Isr: 1,3,2
```

### 查询所有组

```
# ./kafka-consumer-groups.sh --bootstrap-server 10.10.10.232:9092,10.10.10.233:9092,10.10.10.234:9092 --list --command-config /opt/kafka/config/consumer.properties
gray-sender
kafka.eagle.system.group
```

### 查询指定组详细信息

```
# ./kafka-consumer-groups.sh --bootstrap-server 10.10.10.232:9092,10.10.10.233:9092,10.10.10.234:9092 --command-config /opt/kafka/config/consumer.properties   --describe --group gray-sender

GROUP           TOPIC           PARTITION  CURRENT-OFFSET  LOG-END-OFFSET  LAG             CONSUMER-ID                                  HOST            CLIENT-ID
gray-sender     hicore-gray     0          7               7               0               rdkafka-8964fcf7-8d41-4fcb-84a2-431e8d0afdb6 /10.10.10.224   rdkafka
gray-sender     hicore-gray     1          733             733             0               rdkafka-8964fcf7-8d41-4fcb-84a2-431e8d0afdb6 /10.10.10.224   rdkafka
gray-sender     hicore-gray     2          4025            4025            0               rdkafka-8964fcf7-8d41-4fcb-84a2-431e8d0afdb6 /10.10.10.224   rdkafka
```





### 生产者消费者验证

```
# 生产者发送消息
# ./kafka-console-producer.sh --bootstrap-server 10.10.10.232:9092,10.10.10.233:9092,10.10.10.234:9092 --topic Test
# 消费者接收消息
# ./kafka-console-consumer.sh --bootstrap-server=10.10.10.232:9092,10.10.10.233:9092,10.10.10.234:9092 --topic Test --from-beginning
```





