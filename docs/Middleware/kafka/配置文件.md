### 基础配置

```
broker.id=3  
listeners=PLAINTEXT://:9092 
auto.create.topics.enable=false
enable.auto.commit=false
group.initial.rebalance.delay.ms=0
advertised.port=9092
advertised.host.name=np-kafka-03
port=9092
```



### 集群配置

```
acks=1
default.replication.factor=3
min.insync.replicas=2
num.partitions=3          # 需要修改
offsets.topic.replication.factor=3
transaction.state.log.replication.factor=3
transaction.state.log.min.isr=2
```

> acks （Default: 1）

指定了必须要有多少个分区副本收到消息，生产者才认为该消息是写入成功的，这个参数对于消息是否丢失起着重要作用。

- acks=0，表示生产者在成功写入消息之前不会等待任何来自服务器的响应.  换句话说，一旦出现了问题导致服务器没有收到消息，那么生产者就无从得知，消息也就丢失了. 改配置由于不需要等到服务器的响应，所以可以以网络支持的最大速度发送消息，从而达到很高的吞吐量。
- acks=1，表示只要集群的leader分区副本接收到了消息，就会向生产者发送一个成功响应的ack，此时生产者接收到ack之后就可以认为该消息是写入成功的. 一旦消息无法写入leader分区副本(比如网络原因、leader节点崩溃),生产者会收到一个错误响应，当生产者接收到该错误响应之后，为了避免数据丢失，会重新发送数据.这种方式的吞吐量取决于使用的是异步发送还是同步发送.
- acks =all,表示只有所有参与复制的节点(ISR列表的副本)全部收到消息时，生产者才会接收到来自服务器的响应. 这种模式是最高级别的，也是最安全的，可以确保不止一个Broker接收到了消息. 该模式的延迟会很高.

> min.insync.replicas （Default: 1）

当acks=all时，需要所有的副本都同步了才会发送成功响应到生产者. 其实这里面存在一个问题：如果Leader副本是唯一的同步副本时会发生什么呢？此时相当于acks=1.所以是不安全的.

该参数控制的是消息至少被写入到多少个副本才算是"真正写入",该值默认值为1，生产环境设定为一个大于1的值可以提升消息的持久性. 因为如果同步副本的数量低于该配置值，则生产者会收到错误响应，从而确保消息不丢失.



---

> replica.lag.time.max.ms  （Default: 30s）

In-sync replica(ISR)称之为同步副本，ISR中的副本都是与Leader进行同步的副本，所以不在该列表的follower会被认为与Leader是不同步的. 那么，ISR中存在是什么副本呢？首先可以明确的是：Leader副本总是存在于ISR中. 而follower副本是否在ISR中，取决于该follower副本是否与Leader副本保持了“同步”.

* 上面所说的同步不是指完全的同步，即并不是说一旦follower副本同步滞后与Leader副本，就会被踢出ISR列表.
* 该参数表示follower副本滞后与Leader副本的最长时间间隔，默认是30秒.  这就意味着，只要follower副本落后于leader副本的时间间隔不超过30秒，就可以认为该follower副本与leader副本是同步的，所以哪怕当前follower副本落后于Leader副本几条消息，只要在30秒之内赶上Leader副本，就不会被踢出出局.
* 如果follower副本被踢出ISR列表，等到该副本追上了Leader副本的进度，该副本会被再次加入到ISR列表中，所以ISR是一个动态列表，并不是静态不变的。

> retries  （Default:  2147483647）

可以微调在发送失败时，生产者应尝试将消息发送给kafka多少次。默认值为2147483647，其为最大整数。

> delivery.timeout.ms



> max.in.flight.requests.per.connection

该参数指定了生产者在收到服务器晌应之前可以发送多少个消息。它的值越高，就会占用越多的内存，不过也会提升吞吐量。把它设为1可以保证消息是按照发送的顺序写入服务器的，即使发生了重试。



### 网络配置

```
num.network.threads=3
socket.send.buffer.bytes=102400
socket.receive.buffer.bytes=102400
socket.request.max.bytes=104857600
```



### 磁盘配置

```
num.io.threads=8
num.recovery.threads.per.data.dir=1
```



### 日志配置

```
log.dirs=/opt/kafka/logs  # 需要修改
log.retention.hours=168
log.segment.bytes=1073741824
log.retention.check.interval.ms=300000
```







### zk 配置

```
zookeeper.connect=np-zk-01:2181,np-zk-02:2181,np-zk-03:2181
zookeeper.connection.timeout.ms=18000
```



### 认证配置





### 资源配置















> JVM 调整

KAFKA_HEAP_OPTS=" -Xmx2048m -Xms2048m" 

一般HEAP SIZE的大小不超过主机内存的50%。

> 网络和io操作线程配置优化

```
# broker处理消息的最大线程数
num.network.threads=9
# broker处理磁盘IO的线程数
num.io.threads=16
```

num.network.threads主要处理网络io，读写缓冲区数据，基本没有io等待，配置线程数量为cpu核数加1。

num.io.threads主要进行磁盘io操作，高峰期可能有些io等待，因此配置需要大些。配置线程数量为cpu核数2倍，最大不超过3倍。

> 网络套接字

```
# 套接字服务器将接受的请求的最大大小
socket.request.max.bytes=2147483600
```

根据自己业务数据包的大小适当调大。这里取值是int类型的，而受限于java int类型的取值范围（-2147483648~2147483647）。

> 日志写入

```
# 每当producer写入10000条消息时，刷数据到磁盘
log.flush.interval.messages=10000
# 每间隔1秒钟时间，刷数据到磁盘
log.flush.interval.ms=1000
```

为了大幅度提高producer写入吞吐量，需要定期批量写文件。一般无需改动，如果topic的数据量较小可以考虑减少log.flush.interval.ms和log.flush.interval.messages来强制刷写数据，减少可能由于缓存数据未写盘带来的不一致。

> 日志保留

```
# 日志保留时长
log.retention.hours=72
# 段文件配置
log.segment.bytes=1073741824
```

日志建议保留三天，也可以更短；段文件配置1GB，有利于快速回收磁盘空间，重启kafka加载也会加快（kafka启动时是单线程扫描目录(log.dir)下所有数据文件）。如果文件过小，则文件数量比较多。

> replica复制

```
num.replica.fetchers=3
replica.fetch.min.bytes=1
replica.fetch.max.bytes=5242880
```

* 拉取线程数(num.replica.fetchers):fetcher配置多可以提高follower的I/O并发度，单位时间内leader持有更多请求，相应负载会增大，需要根据机器硬件资源做权衡，建议适当调大；

* 最小字节数(replica.fetch.min.bytes):一般无需更改，默认值即可；

* 最大字节数(replica.fetch.max.bytes)：默认为1MB，这个值太小，推荐5M，根据业务情况调整

* 最大等待时间(replica.fetch.wait.max.ms):follow拉取频率，频率过高，leader会积压大量无效请求情况，无法进行数据同步，导致cpu飙升。配置时谨慎使用，建议默认值，无需配置。

> 分区数量

```
num.partitions=3
```

默认partition数量1，如果topic在创建时没有指定partition数量，默认使用此值。Partition的数量选取也会直接影响到Kafka集群的吞吐性能，配置过小会影响消费性能，建议改为3。



